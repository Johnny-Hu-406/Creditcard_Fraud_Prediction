{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11ab4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "import hashlib\n",
    "import time  \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "start_time = time.time() \n",
    "\n",
    "data1 = pd.read_csv(r\"public.csv\")\n",
    "data2 = pd.read_csv(r\"training.csv\")\n",
    "public1 = pd.read_csv(r\"public_processed.csv\")\n",
    "public2 = pd.read_csv(r\"uploadfile.csv\")\n",
    "# public_processed_df = pd.read_csv(r\"uploadfile.csv\")\n",
    "data = pd.concat([data1, data2])\n",
    "public_processed_df = pd.concat([public1, public2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609040, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8688526, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354321, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # public_processed + public\n",
    "# data3 = pd.read_csv(r\"uploadfile.csv\")\n",
    "# data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把特定的資料轉換成整數\n",
    "def hash_to_int(value):\n",
    "    return int(hashlib.sha256(value.encode()).hexdigest(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"chid\"] = data[\"chid\"].apply(hash_to_int)\n",
    "data[\"cano\"] = data[\"cano\"].apply(hash_to_int)\n",
    "data[\"mchno\"]= data[\"mchno\"].apply(hash_to_int)\n",
    "data[\"acqic\"]= data[\"acqic\"].apply(hash_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loctm\n",
    "data['loctm_hh'] = data['loctm'].apply(lambda x: math.floor(x/10000))\n",
    "data['loctm_mm'] = data['loctm'].apply(lambda x: math.floor(x/100)-math.floor(x/10000)*100)\n",
    "data['loctm_ss'] = data['loctm'].apply(lambda x: math.floor(x)-math.floor(x/100)*100)\n",
    "data['weekday'] = data['locdt'] % 7\n",
    "data['conam3000'] = np.where(data['conam'] > 3000, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選取標籤為1的資料\n",
    "df_positive = data[data['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>locdt</th>\n",
       "      <th>loctm</th>\n",
       "      <th>chid</th>\n",
       "      <th>cano</th>\n",
       "      <th>contp</th>\n",
       "      <th>etymd</th>\n",
       "      <th>mchno</th>\n",
       "      <th>acqic</th>\n",
       "      <th>mcc</th>\n",
       "      <th>conam</th>\n",
       "      <th>ecfg</th>\n",
       "      <th>insfg</th>\n",
       "      <th>iterm</th>\n",
       "      <th>bnsfg</th>\n",
       "      <th>flam1</th>\n",
       "      <th>stocn</th>\n",
       "      <th>scity</th>\n",
       "      <th>stscd</th>\n",
       "      <th>ovrlt</th>\n",
       "      <th>flbmk</th>\n",
       "      <th>hcefg</th>\n",
       "      <th>csmcu</th>\n",
       "      <th>csmam</th>\n",
       "      <th>flg_3dsmk</th>\n",
       "      <th>label</th>\n",
       "      <th>loctm_hh</th>\n",
       "      <th>loctm_mm</th>\n",
       "      <th>loctm_ss</th>\n",
       "      <th>weekday</th>\n",
       "      <th>conam3000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b734f1d9c29c8724f7fa9e14127ce19ad4fe0246055cc4...</td>\n",
       "      <td>57</td>\n",
       "      <td>202907</td>\n",
       "      <td>7545112409221137759701891378798041262236146998...</td>\n",
       "      <td>1128851795486469584559058088078669467756395378...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5924423611301616588777091199737320995116083692...</td>\n",
       "      <td>9694665056880918802914193734853718239332787519...</td>\n",
       "      <td>275.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16115.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d3f6a3abc642f90d91562f91933486d5ec3a09416117d1...</td>\n",
       "      <td>58</td>\n",
       "      <td>173408</td>\n",
       "      <td>1749076699796321748633361125960037577495789411...</td>\n",
       "      <td>7440270619593444319564453073679173143151392497...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7379499774345514436123639587863825271999308346...</td>\n",
       "      <td>1006253589440496640027832611063390821766511707...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11380.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20eea5b22fc76d0c1a802b0b43e37135121c19ba3235fa...</td>\n",
       "      <td>57</td>\n",
       "      <td>23759</td>\n",
       "      <td>1386128939984345883611159076460996037107150094...</td>\n",
       "      <td>2957621807105112347001786700780013206935156281...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1295656580959528195878890317272517510574361137...</td>\n",
       "      <td>3396357932789603274781563012123409452058004868...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>3024.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3027</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12381.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72ecbb06661cd74ae4f26828feef5e2ad5da884cbce851...</td>\n",
       "      <td>56</td>\n",
       "      <td>113358</td>\n",
       "      <td>9266034733120664363656227825632130684606573534...</td>\n",
       "      <td>2692235992922997015670407420715992764860752243...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1043994063244910127941407210589116601102921018...</td>\n",
       "      <td>1006253589440496640027832611063390821766511707...</td>\n",
       "      <td>276.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15759.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6123106d4e8e712ec4cc8dcb483a92607c72e939bcd77b...</td>\n",
       "      <td>59</td>\n",
       "      <td>135826</td>\n",
       "      <td>7116076958514668873675520613084165528984827318...</td>\n",
       "      <td>6501428506525536389995197547809427192456469505...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2764270327677967978435929459491199409838445234...</td>\n",
       "      <td>9694665056880918802914193734853718239332787519...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15759.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               txkey  locdt   loctm  \\\n",
       "0  b734f1d9c29c8724f7fa9e14127ce19ad4fe0246055cc4...     57  202907   \n",
       "1  d3f6a3abc642f90d91562f91933486d5ec3a09416117d1...     58  173408   \n",
       "2  20eea5b22fc76d0c1a802b0b43e37135121c19ba3235fa...     57   23759   \n",
       "3  72ecbb06661cd74ae4f26828feef5e2ad5da884cbce851...     56  113358   \n",
       "4  6123106d4e8e712ec4cc8dcb483a92607c72e939bcd77b...     59  135826   \n",
       "\n",
       "                                                chid  \\\n",
       "0  7545112409221137759701891378798041262236146998...   \n",
       "1  1749076699796321748633361125960037577495789411...   \n",
       "2  1386128939984345883611159076460996037107150094...   \n",
       "3  9266034733120664363656227825632130684606573534...   \n",
       "4  7116076958514668873675520613084165528984827318...   \n",
       "\n",
       "                                                cano  contp  etymd  \\\n",
       "0  1128851795486469584559058088078669467756395378...      5    5.0   \n",
       "1  7440270619593444319564453073679173143151392497...      5    4.0   \n",
       "2  2957621807105112347001786700780013206935156281...      5    5.0   \n",
       "3  2692235992922997015670407420715992764860752243...      5    5.0   \n",
       "4  6501428506525536389995197547809427192456469505...      5    4.0   \n",
       "\n",
       "                                               mchno  \\\n",
       "0  5924423611301616588777091199737320995116083692...   \n",
       "1  7379499774345514436123639587863825271999308346...   \n",
       "2  1295656580959528195878890317272517510574361137...   \n",
       "3  1043994063244910127941407210589116601102921018...   \n",
       "4  2764270327677967978435929459491199409838445234...   \n",
       "\n",
       "                                               acqic    mcc   conam  ecfg  \\\n",
       "0  9694665056880918802914193734853718239332787519...  275.0   674.0     1   \n",
       "1  1006253589440496640027832611063390821766511707...  272.0  1262.0     0   \n",
       "2  3396357932789603274781563012123409452058004868...  272.0  3024.0     1   \n",
       "3  1006253589440496640027832611063390821766511707...  276.0   820.0     1   \n",
       "4  9694665056880918802914193734853718239332787519...  288.0  1614.0     0   \n",
       "\n",
       "   insfg  iterm  bnsfg  flam1  stocn    scity  stscd  ovrlt  flbmk  hcefg  \\\n",
       "0      0    0.0      0    677    0.0  16115.0   -1.0      0      0    6.0   \n",
       "1      0    0.0      0   1266    0.0  11380.0   -1.0      0      0    6.0   \n",
       "2      0    0.0      0   3027   42.0  12381.0   -1.0      0      0    6.0   \n",
       "3      0    0.0      0    819    0.0  15759.0   -1.0      0      0    6.0   \n",
       "4      0    0.0      0   1620    0.0  15759.0   -1.0      0      0    6.0   \n",
       "\n",
       "   csmcu  csmam  flg_3dsmk  label  loctm_hh  loctm_mm  loctm_ss  weekday  \\\n",
       "0   70.0    677          0      0        20        29         7        1   \n",
       "1   70.0   1266          0      0        17        34         8        2   \n",
       "2   70.0   3027          0      0         2        37        59        1   \n",
       "3   70.0    819          0      0        11        33        58        0   \n",
       "4   70.0   1620          0      0        13        58        26        3   \n",
       "\n",
       "   conam3000  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locdt</th>\n",
       "      <th>loctm</th>\n",
       "      <th>contp</th>\n",
       "      <th>etymd</th>\n",
       "      <th>mcc</th>\n",
       "      <th>conam</th>\n",
       "      <th>ecfg</th>\n",
       "      <th>insfg</th>\n",
       "      <th>iterm</th>\n",
       "      <th>bnsfg</th>\n",
       "      <th>...</th>\n",
       "      <th>hcefg</th>\n",
       "      <th>csmcu</th>\n",
       "      <th>csmam</th>\n",
       "      <th>flg_3dsmk</th>\n",
       "      <th>label</th>\n",
       "      <th>loctm_hh</th>\n",
       "      <th>loctm_mm</th>\n",
       "      <th>loctm_ss</th>\n",
       "      <th>weekday</th>\n",
       "      <th>conam3000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34140.000000</td>\n",
       "      <td>34210.000000</td>\n",
       "      <td>3.421300e+04</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.00000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34023.000000</td>\n",
       "      <td>33791.000000</td>\n",
       "      <td>3.421300e+04</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.0</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "      <td>34213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.938211</td>\n",
       "      <td>129295.684301</td>\n",
       "      <td>4.929121</td>\n",
       "      <td>5.186936</td>\n",
       "      <td>330.896434</td>\n",
       "      <td>5.003352e+03</td>\n",
       "      <td>0.870985</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.00491</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>5.760544</td>\n",
       "      <td>65.498446</td>\n",
       "      <td>2.872318e+04</td>\n",
       "      <td>0.027358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.637740</td>\n",
       "      <td>28.888493</td>\n",
       "      <td>29.434630</td>\n",
       "      <td>2.775232</td>\n",
       "      <td>0.206062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.451603</td>\n",
       "      <td>74491.812566</td>\n",
       "      <td>0.260695</td>\n",
       "      <td>2.681076</td>\n",
       "      <td>68.729280</td>\n",
       "      <td>2.197956e+04</td>\n",
       "      <td>0.335222</td>\n",
       "      <td>0.020934</td>\n",
       "      <td>0.27806</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178329</td>\n",
       "      <td>15.824453</td>\n",
       "      <td>1.065455e+06</td>\n",
       "      <td>0.163127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.444129</td>\n",
       "      <td>17.325229</td>\n",
       "      <td>17.262945</td>\n",
       "      <td>1.974892</td>\n",
       "      <td>0.404481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>60743.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>143215.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.264570e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.990000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>194315.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>2.990000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.991000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>235957.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2.555812e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>7.473480e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              locdt          loctm         contp         etymd           mcc  \\\n",
       "count  34213.000000   34213.000000  34213.000000  34140.000000  34210.000000   \n",
       "mean      29.938211  129295.684301      4.929121      5.186936    330.896434   \n",
       "std       17.451603   74491.812566      0.260695      2.681076     68.729280   \n",
       "min        0.000000       7.000000      2.000000      0.000000      1.000000   \n",
       "25%       14.000000   60743.000000      5.000000      4.000000    317.000000   \n",
       "50%       30.000000  143215.000000      5.000000      5.000000    324.000000   \n",
       "75%       45.000000  194315.000000      5.000000      8.000000    365.000000   \n",
       "max       59.000000  235957.000000      6.000000     10.000000    500.000000   \n",
       "\n",
       "              conam          ecfg         insfg        iterm         bnsfg  \\\n",
       "count  3.421300e+04  34213.000000  34213.000000  34213.00000  34213.000000   \n",
       "mean   5.003352e+03      0.870985      0.000438      0.00491      0.000029   \n",
       "std    2.197956e+04      0.335222      0.020934      0.27806      0.005406   \n",
       "min    0.000000e+00      0.000000      0.000000      0.00000      0.000000   \n",
       "25%    1.000000e+02      1.000000      0.000000      0.00000      0.000000   \n",
       "50%    1.264570e+03      1.000000      0.000000      0.00000      0.000000   \n",
       "75%    2.990000e+03      1.000000      0.000000      0.00000      0.000000   \n",
       "max    2.555812e+06      1.000000      1.000000     24.00000      1.000000   \n",
       "\n",
       "       ...         hcefg         csmcu         csmam     flg_3dsmk    label  \\\n",
       "count  ...  34023.000000  33791.000000  3.421300e+04  34213.000000  34213.0   \n",
       "mean   ...      5.760544     65.498446  2.872318e+04      0.027358      1.0   \n",
       "std    ...      1.178329     15.824453  1.065455e+06      0.163127      0.0   \n",
       "min    ...      0.000000      0.000000  0.000000e+00      0.000000      1.0   \n",
       "25%    ...      6.000000     68.000000  3.300000e+01      0.000000      1.0   \n",
       "50%    ...      6.000000     70.000000  3.990000e+02      0.000000      1.0   \n",
       "75%    ...      6.000000     70.000000  1.991000e+03      0.000000      1.0   \n",
       "max    ...     10.000000     85.000000  7.473480e+07      1.000000      1.0   \n",
       "\n",
       "           loctm_hh      loctm_mm      loctm_ss       weekday     conam3000  \n",
       "count  34213.000000  34213.000000  34213.000000  34213.000000  34213.000000  \n",
       "mean      12.637740     28.888493     29.434630      2.775232      0.206062  \n",
       "std        7.444129     17.325229     17.262945      1.974892      0.404481  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        6.000000     14.000000     14.000000      1.000000      0.000000  \n",
       "50%       14.000000     29.000000     29.000000      3.000000      0.000000  \n",
       "75%       19.000000     44.000000     44.000000      4.000000      0.000000  \n",
       "max       23.000000     59.000000     59.000000      6.000000      1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etymd', 'mcc', 'stocn', 'scity', 'stscd', 'hcefg', 'csmcu']\n"
     ]
    }
   ],
   "source": [
    "# 列出包含NaN值的列名 並替換\n",
    "nan_columns = data.isnull().any()\n",
    "columns_with_nan = nan_columns[nan_columns].index.tolist()\n",
    "print(columns_with_nan)\n",
    "data[columns_with_nan] = data[columns_with_nan].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['label','txkey'], axis=1) \n",
    "y = data['label']\n",
    "# Step 5 特徵選擇\n",
    "selector = SelectKBest(f_classif, k=\"all\")  # Change k value as needed \n",
    "X_new = selector.fit_transform(X, y)\n",
    "# 獲取選擇的特徵索引\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "# 獲取選擇的特徵名稱\n",
    "selected_feature_names = X.columns[selected_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: locdt, F-score: 25.732720707422157\n",
      "Feature: loctm, F-score: 2246.212048769775\n",
      "Feature: chid, F-score: 67.98372188681121\n",
      "Feature: cano, F-score: 2.1678964497214155\n",
      "Feature: contp, F-score: 89.86191045807381\n",
      "Feature: etymd, F-score: 2099.7801891478725\n",
      "Feature: mchno, F-score: 3622.4818822921243\n",
      "Feature: acqic, F-score: 8890.879309787448\n",
      "Feature: mcc, F-score: 1335.0602606964885\n",
      "Feature: conam, F-score: 4695.318631813367\n",
      "Feature: ecfg, F-score: 12407.180690100618\n",
      "Feature: insfg, F-score: 340.23096985088426\n",
      "Feature: iterm, F-score: 199.74065404429842\n",
      "Feature: bnsfg, F-score: 42.4869143094996\n",
      "Feature: flam1, F-score: 4699.231085728367\n",
      "Feature: stocn, F-score: 258605.04228082276\n",
      "Feature: scity, F-score: 30475.308361969375\n",
      "Feature: stscd, F-score: 1576023.8733040548\n",
      "Feature: ovrlt, F-score: 2219.0180670710456\n",
      "Feature: flbmk, F-score: 1.099339555148631\n",
      "Feature: hcefg, F-score: 2473.0186553035924\n",
      "Feature: csmcu, F-score: 96.94452738684194\n",
      "Feature: csmam, F-score: 1888.0609285778685\n",
      "Feature: flg_3dsmk, F-score: 1507.9343374232183\n",
      "Feature: loctm_hh, F-score: 2237.1577440727146\n",
      "Feature: loctm_mm, F-score: 11.939556585996487\n",
      "Feature: loctm_ss, F-score: 0.4365526259884288\n",
      "Feature: weekday, F-score: 261.8852603727257\n",
      "Feature: conam3000, F-score: 9262.205095887542\n"
     ]
    }
   ],
   "source": [
    "f_scores = selector.scores_\n",
    "for feature_name, f_score in zip(selected_feature_names, f_scores):\n",
    "    print(f\"Feature: {feature_name}, F-score: {f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 切割訓練測試集\n",
    "# Assuming X_new and y are the selected features and labels after feature selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=15)\n",
    "\n",
    "# Step 7 特徵正規化，方便訓練並降低不同訓練資料特徵維度的比例\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma越小越容易Overfitting,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [22:21:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of XGB is  0.8064206223525281\n"
     ]
    }
   ],
   "source": [
    "# model = XGBClassifier(max_depth=20, \n",
    "#                       learning_rate=0.03,\n",
    "#                      min_child_weight=7.734890981711013,\n",
    "#                      scale_pos_weight=5, \n",
    "#                      gamma=0,\n",
    "#                      n_estimators=200, \n",
    "#                      random_state=42, \n",
    "#                      eval_metric=\"auc\",\n",
    "#                      tree_method='hist',  # 使用\"hist\"\n",
    "#                      device='cuda',  # 使用\"cuda\"\n",
    "#                     colsample_bytree=0.7,\n",
    "#                      colsample_bylevel=1,\n",
    "#                     objective='binary:logistic')\n",
    "model = XGBClassifier(max_depth=20, \n",
    "                    min_child_weight=5,\n",
    "                    scale_pos_weight=5, \n",
    "                    n_estimators=200, \n",
    "                    gamma=0,\n",
    "                    eval_metric=\"auc\",\n",
    "                    tree_method='hist',  # 使用\"hist\"\n",
    "                    # max_delta_step =1,\n",
    "                    # colsample_bytree=0.7,\n",
    "                    # colsample_bylevel=1,\n",
    "                    seed=1440,\n",
    "                    device='cuda')  # 使用\"cuda\"\n",
    "# model = xgb.XGBClassifier(\n",
    "#     max_depth=8,\n",
    "#     learning_rate=0.03,\n",
    "#     n_estimators=500, \n",
    "#     scale_pos_weight=5, \n",
    "#     silent=True,\n",
    "#     objective='binary:logistic',\n",
    "#     nthread=-1,\n",
    "#     gamma=0,\n",
    "#     min_child_weight=0,\n",
    "#     subsample=0.85,\n",
    "#     colsample_bytree=0.7,\n",
    "#     colsample_bylevel=1,\n",
    "#     scoring='roc_auc',                  \n",
    "#     seed=1440,\n",
    "#     tree_method='hist',  # 使用\"hist\"\n",
    "#     device='cuda'\n",
    "#     # missing=None\n",
    "#     )\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "print(\"CV score of XGB is \",cross_val_score(model,X_train,y_train,cv=4, scoring = 'f1').mean())\n",
    "\n",
    "# Step 9: Model Evaluation\n",
    "# y_trainpred = model.predict(X_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# print(\"TrainingData Classification Report: \")\n",
    "# print(classification_report(y_train, y_trainpred))\n",
    "# print(confusion_matrix(y_train, y_trainpred))\n",
    "# print('*'*20)\n",
    "# print(\"y_pred Classification Report: \")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(\"Confusion Matrix: \")\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1852570\n",
      "           1       0.92      0.76      0.83      6944\n",
      "\n",
      "    accuracy                           1.00   1859514\n",
      "   macro avg       0.96      0.88      0.92   1859514\n",
      "weighted avg       1.00      1.00      1.00   1859514\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1852124     446]\n",
      " [   1678    5266]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"y_pred Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.138233 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2679\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.119252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.130459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20451, number of negative: 5558088\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2646\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.141206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604978\n",
      "[LightGBM] [Info] Start training from score -5.604978\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "CV score of LGBM is  0.5536282117291258\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbmmodel = LGBMClassifier(random_state=42,\n",
    "                        n_estimators = 500,\n",
    "                        # scale_pos_weight=2,\n",
    "                        max_depth = 10,\n",
    "                        learning_rate =  0.025,\n",
    "                         boosting_type = 'gbdt',\n",
    "                        device=\"gpu\")\n",
    "print(\"CV score of LGBM is \",cross_val_score(lgbmmodel,X_train,y_train,cv=4, scoring = 'f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 27269, number of negative: 7410783\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2692\n",
      "[LightGBM] [Info] Number of data points in the train set: 7438052, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (141.87 MB) transferred to GPU in 0.166771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604941\n",
      "[LightGBM] [Info] Start training from score -5.604941\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "y_pred Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1852570\n",
      "           1       0.69      0.45      0.55      6944\n",
      "\n",
      "    accuracy                           1.00   1859514\n",
      "   macro avg       0.85      0.73      0.77   1859514\n",
      "weighted avg       1.00      1.00      1.00   1859514\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1851186    1384]\n",
      " [   3808    3136]]\n"
     ]
    }
   ],
   "source": [
    "lgbmmodel.fit(X_train,y_train)\n",
    "y_pred = lgbmmodel.predict(X_test)\n",
    "\n",
    "print(\"y_pred Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline DART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.104377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2679\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.093719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.097820 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Info] Number of positive: 20451, number of negative: 5558088\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2646\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.087559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604978\n",
      "[LightGBM] [Info] Start training from score -5.604978\n",
      "CV score of DART is  0.8749131635428594\n"
     ]
    }
   ],
   "source": [
    "dartmodel = LGBMClassifier(random_state = 42, device=\"gpu\", boosting_type = 'dart')\n",
    "print(\"CV score of DART is \",cross_val_score(dartmodel,X_train,y_train,cv=4, scoring = 'roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 27269, number of negative: 7410783\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2692\n",
      "[LightGBM] [Info] Number of data points in the train set: 7438052, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (141.87 MB) transferred to GPU in 0.127994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604941\n",
      "[LightGBM] [Info] Start training from score -5.604941\n"
     ]
    }
   ],
   "source": [
    "dartmodel.fit(X_train,y_train)\n",
    "y_pred = dartmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1852570\n",
      "           1       0.68      0.36      0.47      6944\n",
      "\n",
      "    accuracy                           1.00   1859514\n",
      "   macro avg       0.84      0.68      0.73   1859514\n",
      "weighted avg       1.00      1.00      1.00   1859514\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1851417    1153]\n",
      " [   4456    2488]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.091036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.087581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2679\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.085408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2679\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.088860 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.090151 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Info] Number of positive: 20452, number of negative: 5558087\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2687\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.098984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604929\n",
      "[LightGBM] [Info] Start training from score -5.604929\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 20451, number of negative: 5558088\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2646\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.090159 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604978\n",
      "[LightGBM] [Info] Start training from score -5.604978\n",
      "[LightGBM] [Info] Number of positive: 20451, number of negative: 5558088\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2646\n",
      "[LightGBM] [Info] Number of data points in the train set: 5578539, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (106.40 MB) transferred to GPU in 0.095214 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604978\n",
      "[LightGBM] [Info] Start training from score -5.604978\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "CV score of VC is  0.989385581247138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vcmodel = VotingClassifier([(\"lgbm\",lgbmmodel),(\"xgb\",model),(\"dart\",dartmodel)],voting=\"soft\",weights=[1, 3, 2])\n",
    "print(\"CV score of VC is \",cross_val_score(vcmodel,X_train,y_train,cv=4, scoring = 'roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 27269, number of negative: 7410783\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2692\n",
      "[LightGBM] [Info] Number of data points in the train set: 7438052, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (141.87 MB) transferred to GPU in 0.130500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604941\n",
      "[LightGBM] [Info] Start training from score -5.604941\n",
      "[LightGBM] [Info] Number of positive: 27269, number of negative: 7410783\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2692\n",
      "[LightGBM] [Info] Number of data points in the train set: 7438052, number of used features: 29\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 17 dense feature groups (141.87 MB) transferred to GPU in 0.125163 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003666 -> initscore=-5.604941\n",
      "[LightGBM] [Info] Start training from score -5.604941\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "y_pred Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1852570\n",
      "           1       0.91      0.65      0.76      6944\n",
      "\n",
      "    accuracy                           1.00   1859514\n",
      "   macro avg       0.95      0.83      0.88   1859514\n",
      "weighted avg       1.00      1.00      1.00   1859514\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1852097     473]\n",
      " [   2418    4526]]\n"
     ]
    }
   ],
   "source": [
    "vcmodel.fit(X_train,y_train)\n",
    "y_pred = vcmodel.predict(X_test)\n",
    "\n",
    "# print(\"TrainingData Classification Report: \")\n",
    "# print(classification_report(y_train, y_trainpred))\n",
    "# print(confusion_matrix(y_train, y_trainpred))\n",
    "# print('*'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1852570\n",
      "           1       0.91      0.65      0.76      6944\n",
      "\n",
      "    accuracy                           1.00   1859514\n",
      "   macro avg       0.95      0.83      0.88   1859514\n",
      "weighted avg       1.00      1.00      1.00   1859514\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1852097     473]\n",
      " [   2418    4526]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "public1 = pd.read_csv(r\"public_processed.csv\")\n",
    "public2 = pd.read_csv(r\"private_1_processed.csv\")\n",
    "public_processed_df = pd.concat([public1, public2])\n",
    "\n",
    "public_feature = public_processed_df.drop(['txkey'], axis=1)\n",
    "public_name = public_processed_df['txkey']\n",
    "\n",
    "public_feature[\"chid\"] = public_feature[\"chid\"].apply(hash_to_int)\n",
    "public_feature[\"cano\"] = public_feature[\"cano\"].apply(hash_to_int)\n",
    "public_feature[\"mchno\"]= public_feature[\"mchno\"].apply(hash_to_int)\n",
    "public_feature[\"acqic\"]= public_feature[\"acqic\"].apply(hash_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_feature['loctm_hh'] = public_feature['loctm'].apply(lambda x: math.floor(x/10000))\n",
    "public_feature['loctm_mm'] = public_feature['loctm'].apply(lambda x: math.floor(x/100)-math.floor(x/10000)*100)\n",
    "public_feature['loctm_ss'] = public_feature['loctm'].apply(lambda x: math.floor(x)-math.floor(x/100)*100)\n",
    "public_feature['weekday'] = public_feature['locdt'] % 7\n",
    "public_feature['conam3000'] = np.where(public_feature['conam'] > 3000, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etymd', 'mcc', 'stocn', 'scity', 'stscd', 'hcefg', 'csmcu']\n"
     ]
    }
   ],
   "source": [
    "#  自己設計的資料清理\n",
    "public_feature_nan_columns = public_feature.isnull().any()\n",
    "public_feature_columns_with_nan = public_feature_nan_columns[public_feature_nan_columns].index.tolist()\n",
    "print(public_feature_columns_with_nan)\n",
    "public_feature[public_feature_columns_with_nan] = public_feature[public_feature_columns_with_nan].fillna(-1)\n",
    "public_training_5 = public_feature[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#  使用訓練集的sc進行縮放\n",
    "public_X_new = sc.transform(public_training_5)\n",
    "\n",
    "# 使用上面的xgbc測試集辨識\n",
    "public_y_pred = model.predict(public_X_new)\n",
    "\n",
    "# 製作與儲存可以上傳的csv檔案\n",
    "public_y_pred = pd.DataFrame(public_y_pred, columns=[\"pred\"])\n",
    "\n",
    "public_y_pred = public_y_pred.reset_index(drop=True)\n",
    "public_name = public_name.reset_index(drop=True)\n",
    "\n",
    "result = pd.concat([public_name, public_y_pred], axis=1)\n",
    "result.to_csv(r\"result.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
